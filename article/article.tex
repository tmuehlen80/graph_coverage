\documentclass{article}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{graphicx}

\title{A Graph-based Framework for Coverage Analysis in Autonomous Driving}
\author{xxx}
\date{\today}

\begin{document}

\maketitle

\section{Abstract}


\section{Introduction}



\begin{itemize}
    \item In autonomous driving, coverage analysis is a crucial step to ensure the safety and reliability of the system.
    \item In most situations, coverage arguments are collected either per coverage factor, or maybe up to 2 or 3 factor interactions.
    \item See for example \cite{foretellix2019} for an production grade implementation of state of the art coverage analysis.
    \item In contrast to existing approaches, this paper proposes a graph-based framework for coverage analysis.
    \item There are already other graph-based approaches for analysing and representing traffic scenes, see for example \cite{behr2021graph}.
    \item However, the work in that paper is not specifically focused on coverage analysis.
    \item Hence in this paper, graph based traffic scene representations are utilized for coverage analysis.
    \item This paper is structured as follows:
    \begin{itemize}
        \item In the first section, xxx
    \end{itemize}
\end{itemize}


\cite{wagner2022odd}

\cite{arzamasov2021data}



\section{exsting coverage and analysis approaches}

add Master thesis Johannes

\cite{pegasus2019method}

\cite{Ries2021traj_clustering}

\cite{ORAD2021taxonomy}

\cite{Ulbrich2015scene}

\cite{DBLP:journals/corr/abs-1801-08598}

\cite{Ammann_Offutt_2008}

\cite{foretellix2019}

\cite{deGelder2022ontology}

\cite{wachenfeld2016release}

\cite{berger2020survey}

\cite{iso21448}

\cite{ul4600}


\section{Defining a traffic scene graph}

\cite{behr2021graph}



\cite{newman2010networks}

\cite{bagheri2020ontology}

\cite{riedmaier2020realistic}


\cite{fremont2020scenic}

\cite{pek2019generating}

\subsection{time based graph representations}

\section{Analysing a traffic scene with agraph}


\begin{itemize}
    \item Having defined a graph-based traffic scene representation, we can now analyse the coverage of the system.
    \item Two methodologies are proposed for this purpose:
    \item One is to define archetypes of traffice scenes, and to compare graphs from observed traffic scenes to these archetypes.
    \item The second one is to translate graphs to graph embeddings, and then to compare the embeddings of different sets of traffic scenes.
\end{itemize}

\section{Create subgraphs for coverage analysis}

\begin{itemize}
    \item There is a lot of knowledge in the literature on how to define archetypes of traffic scenes.
    \item Once an archetype is defined, a special property of graphs can be used. 
    \item Two graphs are isomorphic if they have the same structure, regardless of the node and edge labels.
    \item As the archetypes are not necessarily are involving a lot of actors, these are more like subsets of actual traffic scenes.
    \item A very simple example might be 2 vehicles on the same lane, driving in the same direction and another vehicle driving on a neighboring lane.
    \item This situation can be represented by a graph with 3 nodes and 2 edges. 
    \item In most real traffic situations however, there will be additional actors present, so that we are not searching for isomorphic graphs, but rather want to check if any subgraph of $G$ is isomorphic to the archetype graph $A$.
    \item This is an example of a subgraph isomorphism problem.
    \item While this problem is NP-hard, the graphs considered here are rather small, so the computational time is reasonable.
    \item One such algorithm is the VF2 algorithm, which is implemented in the NetworkX library (see \cite{cordella2004subgraph}).
    \item The strategy we are then applying is the following:
    \item \begin{enumerate}
            \item Define a set of subgraphs $S$ that are considered to be archetypes.
            \item Define which node and edge attributes are considered for the isomorphism check.
            \item Create an empty dataframe $C$ with a column for each subgraph in $S$
            \item Define the set of traffice scenes (e.g. from Carla or Argoverse) defined as graphs $G$
            \item For each graph $G$, check if any subgraph of $G$ is isomorphic to any subgraph in $S$ and note the result in a new row in table $C$
        \end{enumerate}
    \item This strategy can be described to some degree as a bottom up approach: Starting from a detail level, individual situations are defined.
    \item Then going upwards to different datasets, it is checked, if the archetype is present.
    \item Also, follow up analysis of the created coverage dataframe can be performed. For example,
    \item \begin{itemize}
        \item The distribution of numeric attributes like speed and and distance to other actors can be visualized for the subset of all traffic scenes which are subgraph isomorphic to an archetype.
        \item It can be cross tabulated, which combinations of archetypes are jointly present in a traffic scene.
        \item Pass Fail rates or other AV performance metrics can be calculated for the subset of all traffic scenes which are subgraph isomorphic to an archetype.
    \end{itemize}
    \end{itemize}

    

\section{Implementation of Graph Embeddings for Traffic Scene Analysis}

This section describes the concepts, implementation and application of graph embeddings to traffic scene graphs. 
The implementation follows a comprehensive approach to learning graph representations through self-supervised 
contrastive learning.

Embeddings are a widely used method to translate raw data like images or text into an embedding space in order to be 
able to perform machine learning tasks on them. One well known example of this is the Word2Vec model, which is used to 
translate words into a 
vector space, where the distance between vectors can be used to measure the similarity between 
words (\cite{mikolov2013efficientestimationwordrepresentations}).

In the context of traffic scene graphs, embeddings are used to translate the graph structure into a vector space, 
where the distance between vectors can be used to measure the similarity between traffic scenes.
This is useful for coverage analysis, as it allows to compare traffic scenes among each other.
For example, two traffic scenes can be considered similar if the distance between their embeddings is small. This enables
to search for a most similar simulation scenario given a real world scenario, to identify areas with near duplicates or 
to easily visualize structures in the embedding space, which in the original space of all possible traffic scenes
would not be possible.

Graph neural networks (GNNs) are a class of neural networks that are designed to process graph-structured data and have 
gained a lot of popularity in the last years, see for example (add references).

In this paper, a network architecture using a Graph Isomorphism Network with Edge features (GINE) as described 
in \cite{hu2020strategiespretraininggraphneural} is used to generate embeddings for traffic scene graphs as implemented in the 
pytorch geometric library (\cite{Fey/Lenssen/2019}). Main reason for using this specific architecture is that is capable of
learning embedding representations not only on the graph structure itself but on both node and edge attributes. Other 
network architectures like GraphSAGE or GAT are not capable of this. (TODO: check if this is true)


The exact architecture of the model is shown in Figure \ref{fig:model_architecture}. The features used are the actor type (as a one hot encoding),
the actor speed (float), if the actor is on an intersection (boolean) and if the actor changed its lane since the last timestep (boolean) for the nodes.
For the edges, the edge type (as a one hot encoding) and the path length (float) between the two nodes are used.


The core component is the \texttt{TrainableGraphGINE} class, which implements a Graph Isomorphism Network with Edge features (GINE) architecture for generating graph-level embeddings. The model consists of multiple GINE convolutional layers, each containing:
\begin{itemize}
    \item Sequential multi-layer perceptrons (MLPs) with batch normalization and ReLU activations
    \item Edge-aware message passing incorporating both node and edge features
    \item Dropout regularization to prevent overfitting
\end{itemize}

The model employs a combination of three graph pooling strategies - mean, max, and sum pooling - to create a comprehensive graph-level representation. A projection head enables contrastive learning through InfoNCE loss, while an optional classification head supports supervised learning tasks.

\subsection{Data Processing and Augmentation}

The \texttt{GraphDataset} class handles the conversion from NetworkX graphs to PyTorch Geometric format through the \texttt{networkx\_to\_pyg} function. This conversion includes:
\begin{itemize}
    \item One-hot encoding of categorical node features (actor types: VEHICLE, PEDESTRIAN, CYCLIST, MOTORCYCLE)
    \item One-hot encoding of edge types (neighbor\_vehicle, opposite\_vehicle, same\_lane, adjacent\_lane, following, intersection)
    \item Preservation of continuous features such as longitudinal speed and path length
\end{itemize}

Data augmentation is implemented through the \texttt{augment\_graph} function, which adds Gaussian noise to continuous features to create augmented versions for contrastive learning.

\subsection{Training Methodology}

The training process utilizes self-supervised contrastive learning with the following characteristics:
\begin{itemize}
    \item InfoNCE contrastive loss implemented in the \texttt{contrastive\_loss} function
    \item Adaptive learning rate schedule with exponential decay (starting at 0.02, decaying by factor 0.75)
    \item Multi-epoch training with 15 epochs per learning rate stage
    \item Data from both CARLA simulator (4,442 graphs) and Argoverse 2.0 dataset (3,588 graphs)
\end{itemize}

\subsection{Embedding Analysis and Visualization}

The trained model generates 256-dimensional embeddings for each traffic scene graph. Analysis includes:
\begin{itemize}
    \item Dimensionality reduction using Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE)
    \item Visualization of embedding space distinguishing between CARLA and Argoverse data sources
    \item Similarity-based scene retrieval using squared Euclidean distance in embedding space
    \item Integration with visualization functions (\texttt{plot\_lane\_map\_advanced}, \texttt{add\_actors\_to\_map}, \texttt{add\_actor\_edges\_to\_map}) to display similar traffic scenes
\end{itemize}

The implementation demonstrates successful learning of traffic scene representations, with the embedding space capturing meaningful similarities between scenes from different data sources while maintaining distinction between simulation and real-world data.

\section{Application}

\subsection{Argoverse 2.0}

\cite{Argoverse2}

\subsection{Carla}

CARLA (Car Learning to Act, \cite{Dosovitskiy17Carla}) is an open-source simulator specifically designed for autonomous driving research and 
development. It provides a highly realistic urban driving environment with 
diverse road layouts, weather conditions, and traffic scenarios. The simulator features a comprehensive 
sensor suite simulation, flexible API for scenario creation, and supports both learning-based 
and traditional autonomous driving approaches. CARLA enables researchers to test and 
validate autonomous vehicle systems in a safe, controllable environment before real-world deployment.

The simulator has gained widespread adoption across both academic and industrial settings. In research, CARLA serves as a standard platform for developing and 
benchmarking autonomous driving algorithms, including reinforcement learning approaches for vehicle control and sensor fusion 
techniques \cite{codevilla2019exploringlimitationsbehaviorcloning}. Industry applications include 
virtual testing of production autonomous vehicle systems, scenario-based validation pipelines, and integration 
with hardware-in-the-loop testing frameworks \cite{jaeger2023hiddenbiasesendtoenddriving}. CARLA 
is also extensively used in autonomous driving competitions and challenges, providing a common evaluation 
environment for comparing different approaches across research groups worldwide.


Here, Carla version $0.9.15$ is used. The CARLA version $0.10.0$ is not used, because it had only 2 maps and
Mine\_1 (which is not really normal roads) at the start of this project.
Specifically, the following maps were used: Town01, Town02, Town03, Town04, Town05 and Town07. Plots
of these maps are shown in Figure \ref{fig:carla_maps}.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{plots/carla_maps_used.png}
\caption{Overview of CARLA maps used in the simulation study: Town01, Town02, Town03, Town04, Town05, and Town07. These maps provide diverse urban driving environments with varying road layouts, intersections, and traffic patterns.}
\label{fig:carla_maps}
\end{figure}

The data generation script implements sophisticated behavior control mechanisms to create 
diverse and realistic traffic scenarios. Multiple vehicle types including trucks, motorcycles, 
and regular cars are spawned with varying probabilities, each exhibiting different behavioral
characteristics such as speed preferences, following distances, and lane-changing tendencies. 
The script incorporates dynamic behavior modifications during simulation, including random slowdowns, 
periodic behavior changes, and adaptive responses to traffic conditions, resulting in rich and 
varied traffic scene data across multiple CARLA maps and simulation iterations. The simulation runs
have between 20 and 60 vehicles each.

The resulting data consists of xxx scenes with 11 seconds of simulation time each, in order to have a 
similar data size as the Argoverse 2.0 dataset.



% \cite{goodfellow2016deep} % needed?


\section{Summary}

\bibliographystyle{plain}
\bibliography{lit}

\end{document}