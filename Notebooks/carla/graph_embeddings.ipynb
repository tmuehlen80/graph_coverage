{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f802ebec",
   "metadata": {},
   "source": [
    "### Evaluate options for graph embeddings\n",
    "\n",
    "some useful references:\n",
    "\n",
    "- https://distill.pub/2021/gnn-intro/\n",
    "- https://web.stanford.edu/class/cs224w/\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11ae5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define mappings for one-hot encodings\n",
    "ACTOR_TYPE_MAPPING = {\n",
    "    'VEHICLE': 0,\n",
    "    'PEDESTRIAN': 1,\n",
    "    'CYCLIST': 2,\n",
    "    'MOTORCYCLE': 3,\n",
    "    # Add more types as needed\n",
    "}\n",
    "\n",
    "EDGE_TYPE_MAPPING = {\n",
    "    'neighbor_vehicle': 0,\n",
    "    'opposite_vehicle': 1,\n",
    "    'same_lane': 2,\n",
    "    'adjacent_lane': 3,\n",
    "    'following': 4,\n",
    "    'intersection': 5,\n",
    "    # Add more edge types as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf542c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get feature dimensions\n",
    "def get_feature_dimensions(actor_type_mapping=None, edge_type_mapping=None):\n",
    "    \"\"\"Get the dimensions of node and edge features\"\"\"\n",
    "    if actor_type_mapping is None:\n",
    "        actor_type_mapping = ACTOR_TYPE_MAPPING\n",
    "    if edge_type_mapping is None:\n",
    "        edge_type_mapping = EDGE_TYPE_MAPPING\n",
    "    \n",
    "    # Node features: 1 (lon_speed) + num_actor_types (one-hot)\n",
    "    node_features = 1 + len(actor_type_mapping)\n",
    "    \n",
    "    # Edge features: 1 (path_length) + num_edge_types (one-hot)\n",
    "    edge_features = 1 + len(edge_type_mapping)\n",
    "    \n",
    "    return node_features, edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a947a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def networkx_to_pyg(nx_graph, actor_type_mapping=None, edge_type_mapping=None):\n",
    "    \"\"\"\n",
    "    Convert NetworkX graph to PyTorch Geometric Data object.\n",
    "    \n",
    "    Args:\n",
    "        nx_graph: NetworkX graph with node and edge attributes\n",
    "        actor_type_mapping: Dict mapping actor types to indices\n",
    "        edge_type_mapping: Dict mapping edge types to indices\n",
    "    \n",
    "    Returns:\n",
    "        PyTorch Geometric Data object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use default mappings if none provided\n",
    "    if actor_type_mapping is None:\n",
    "        actor_type_mapping = ACTOR_TYPE_MAPPING\n",
    "    if edge_type_mapping is None:\n",
    "        edge_type_mapping = EDGE_TYPE_MAPPING\n",
    "    \n",
    "    # Get node mapping (NetworkX nodes might not be sequential integers)\n",
    "    nodes = list(nx_graph.nodes())\n",
    "    node_mapping = {node: idx for idx, node in enumerate(nodes)}\n",
    "    num_nodes = len(nodes)\n",
    "    \n",
    "    # Extract node features\n",
    "    node_features = []\n",
    "    for node in nodes:\n",
    "        node_data = nx_graph.nodes[node]\n",
    "        \n",
    "        # Extract lon_speed (continuous feature)\n",
    "        lon_speed = node_data.get('lon_speed', 0.0)\n",
    "        \n",
    "        # Extract actor_type and convert to one-hot\n",
    "        actor_type = node_data.get('actor_type')\n",
    "        if hasattr(actor_type, 'value'):  # Handle enum\n",
    "            actor_type_str = actor_type.value\n",
    "        else:\n",
    "            actor_type_str = str(actor_type)\n",
    "        \n",
    "        # Get actor type index\n",
    "        actor_type_idx = actor_type_mapping.get(actor_type_str, 0)  # Default to 0 if unknown\n",
    "        \n",
    "        # Create one-hot encoding for actor type\n",
    "        num_actor_types = len(actor_type_mapping)\n",
    "        actor_onehot = [0.0] * num_actor_types\n",
    "        actor_onehot[actor_type_idx] = 1.0\n",
    "        \n",
    "        # Combine features: [lon_speed, actor_type_onehot...]\n",
    "        node_feature = [lon_speed] + actor_onehot\n",
    "        node_features.append(node_feature)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # Extract edges and edge features\n",
    "    edge_index = []\n",
    "    edge_features = []\n",
    "    \n",
    "    for source, target, edge_data in nx_graph.edges(data=True):\n",
    "        # Map node IDs to indices\n",
    "        source_idx = node_mapping[source]\n",
    "        target_idx = node_mapping[target]\n",
    "        \n",
    "        edge_index.append([source_idx, target_idx])\n",
    "        \n",
    "        # Extract path_length (continuous feature)\n",
    "        path_length = edge_data.get('path_length', 0.0)\n",
    "        \n",
    "        # Extract edge_type and convert to one-hot\n",
    "        edge_type = edge_data.get('edge_type', 'unknown')\n",
    "        edge_type_idx = edge_type_mapping.get(edge_type, 0)  # Default to 0 if unknown\n",
    "        \n",
    "        # Create one-hot encoding for edge type\n",
    "        num_edge_types = len(edge_type_mapping)\n",
    "        edge_onehot = [0.0] * num_edge_types\n",
    "        edge_onehot[edge_type_idx] = 1.0\n",
    "        \n",
    "        # Combine features: [path_length, edge_type_onehot...]\n",
    "        edge_feature = [path_length] + edge_onehot\n",
    "        edge_features.append(edge_feature)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_features, dtype=torch.float)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1 + len(edge_type_mapping)), dtype=torch.float)\n",
    "    \n",
    "    # Create PyG Data object\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846084b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enhanced model with training capabilities\n",
    "class TrainableGraphGINE(torch.nn.Module):\n",
    "    def __init__(self, node_features, edge_features, embedding_dim=128, hidden_dim=64, num_layers=3, num_classes=None):\n",
    "        \"\"\"\n",
    "        GINE model for graph-level embeddings with optional classification\n",
    "        \n",
    "        Args:\n",
    "            node_features: Number of node features\n",
    "            edge_features: Number of edge features  \n",
    "            embedding_dim: Final embedding dimension\n",
    "            hidden_dim: Hidden layer dimension\n",
    "            num_layers: Number of GINE layers\n",
    "            num_classes: Number of classes for supervised learning (None for unsupervised)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # GINE layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.convs.append(\n",
    "            GINEConv(\n",
    "                torch.nn.Sequential(\n",
    "                    torch.nn.Linear(node_features, hidden_dim),\n",
    "                    torch.nn.BatchNorm1d(hidden_dim),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "                ),\n",
    "                edge_dim=edge_features\n",
    "            )\n",
    "        )\n",
    "        self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(\n",
    "                GINEConv(\n",
    "                    torch.nn.Sequential(\n",
    "                        torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                        torch.nn.BatchNorm1d(hidden_dim),\n",
    "                        torch.nn.ReLU(),\n",
    "                        torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "                    ),\n",
    "                    edge_dim=edge_features\n",
    "                )\n",
    "            )\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Graph-level pooling and embedding projection\n",
    "        self.embedding_proj = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim * 3, embedding_dim),  # *3 for mean+max+sum pooling\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Projection head for contrastive learning (unsupervised)\n",
    "        self.projection_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embedding_dim, embedding_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(embedding_dim, embedding_dim // 2)\n",
    "        )\n",
    "        \n",
    "        # Classification head (supervised)\n",
    "        if num_classes is not None:\n",
    "            self.classifier = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(0.3),\n",
    "                torch.nn.Linear(embedding_dim, num_classes)\n",
    "            )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Handle empty edge attributes\n",
    "        if edge_attr.size(0) == 0:\n",
    "            edge_attr = None\n",
    "        \n",
    "        # GINE layers\n",
    "        for i, (conv, bn) in enumerate(zip(self.convs, self.batch_norms)):\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = bn(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        # Graph-level pooling\n",
    "        mean_pool = global_mean_pool(x, batch)\n",
    "        max_pool = global_max_pool(x, batch)\n",
    "        sum_pool = global_add_pool(x, batch)\n",
    "        \n",
    "        # Concatenate pooling strategies\n",
    "        graph_repr = torch.cat([mean_pool, max_pool, sum_pool], dim=1)\n",
    "        \n",
    "        # Final embedding\n",
    "        embeddings = self.embedding_proj(graph_repr)\n",
    "        \n",
    "        outputs = {'embeddings': embeddings}\n",
    "        \n",
    "        # Add projection for contrastive learning\n",
    "        outputs['projection'] = self.projection_head(embeddings)\n",
    "        \n",
    "        # Add classification if applicable\n",
    "        if hasattr(self, 'classifier'):\n",
    "            outputs['logits'] = self.classifier(embeddings)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def get_embedding(self, data):\n",
    "        \"\"\"Extract embeddings only\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(data)\n",
    "            return outputs['embeddings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a95300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrastive loss\n",
    "def contrastive_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"InfoNCE contrastive loss\"\"\"\n",
    "    batch_size = z1.size(0)\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim_matrix = torch.mm(z1, z2.t()) / temperature\n",
    "    \n",
    "    # Labels for positive pairs (diagonal)\n",
    "    labels = torch.arange(batch_size, device=z1.device)\n",
    "    \n",
    "    return F.cross_entropy(sim_matrix, labels)\n",
    "\n",
    "# Data augmentation for contrastive learning\n",
    "def augment_graph(data):\n",
    "    \"\"\"Simple graph augmentation\"\"\"\n",
    "    augmented_data = data.clone()\n",
    "    \n",
    "    # Add noise to continuous features\n",
    "    # Node features: first feature is lon_speed\n",
    "    if augmented_data.x.size(1) > 0:\n",
    "        augmented_data.x[:, 0] += torch.randn_like(augmented_data.x[:, 0]) * 0.1\n",
    "    \n",
    "    # Edge features: first feature is path_length\n",
    "    if augmented_data.edge_attr.size(0) > 0 and augmented_data.edge_attr.size(1) > 0:\n",
    "        augmented_data.edge_attr[:, 0] += torch.randn_like(augmented_data.edge_attr[:, 0]) * 0.1\n",
    "    \n",
    "    return augmented_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed14f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "node_dim, edge_dim = get_feature_dimensions()\n",
    "model = TrainableGraphGINE(node_dim, edge_dim, 256, 96, 4).to(device)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762aa800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_paths):\n",
    "        self.graph_paths = graph_paths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graph_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.graph_paths[idx]\n",
    "        with open(file_path, 'rb') as f:\n",
    "            nx_graph = pickle.load(f)\n",
    "        pyg_data = networkx_to_pyg(nx_graph)\n",
    "        return pyg_data, file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460ac472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmuehlen/.cache/pypoetry/virtualenvs/graph-creator-_1ofKhL9-py3.10/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "graph_paths = glob.glob(\"/home/tmuehlen/repos/graph_coverage/actor_graphs/carla/*.pkl\")\n",
    "dataset = []\n",
    "\n",
    "# for path in graph_paths:\n",
    "#    with open(path, 'rb') as f:\n",
    "#        nx_graph = pickle.load(f)\n",
    "#    pyg_data = networkx_to_pyg(nx_graph)\n",
    "#    dataset.append(pyg_data)\n",
    "\n",
    "graph_ds = GraphDataset(graph_paths)\n",
    "# Data loader\n",
    "#train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(graph_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43da65c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2025-08-23 23:19:38.811319',\n",
       " '2025-08-24 13:09:53.255648',\n",
       " '2025-08-24 13:26:57.295150',\n",
       " '2025-08-24 13:30:03.751131',\n",
       " '2025-08-24 13:32:59.428368',\n",
       " '2025-08-24 13:39:13.698326',\n",
       " '2025-08-24 13:43:23.995928',\n",
       " '2025-08-25 22:13:36.453956',\n",
       " '2025-08-25 22:15:25.146980',\n",
       " '2025-08-25 22:17:26.441626',\n",
       " '2025-08-25 22:31:44.757262',\n",
       " '2025-08-25 22:32:52.848707',\n",
       " '2025-08-27 22:37:11.487023',\n",
       " '2025-08-27 22:38:34.861141',\n",
       " '2025-08-27 22:42:35.846630',\n",
       " '2025-08-30 21:46:28.006975',\n",
       " '2025-08-30 21:50:42.400301',\n",
       " '2025-08-30 21:54:29.005142',\n",
       " '2025-08-30 22:08:30.926841',\n",
       " '2025-08-30 22:13:29.870307',\n",
       " '2025-08-30 22:16:29.872627',\n",
       " '2025-08-30 22:18:25.433697',\n",
       " '2025-08-30 22:20:23.195071',\n",
       " '2025-08-30 22:22:27.597921',\n",
       " '2025-08-30 22:23:13.009936',\n",
       " '2025-08-30 22:24:14.699788',\n",
       " '2025-08-30 22:25:07.988099',\n",
       " '2025-08-30 22:26:09.200293',\n",
       " '2025-08-30 22:26:55.620015',\n",
       " '2025-08-30 22:28:18.847801'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([path.split(\"/\")[-1].split(\"_\")[1] for path in graph_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf0324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_ds.__getitem__(10)\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439208b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f476c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5883\n",
      "Epoch 1, Loss: 0.3529\n",
      "Epoch 2, Loss: 0.3017\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "   \n",
    "    for batch in train_loader:\n",
    "        batch = batch[0].to(device)\n",
    "        aug_batch = augment_graph(batch).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs1 = model(batch)\n",
    "        outputs2 = model(aug_batch)\n",
    "\n",
    "        loss = contrastive_loss(outputs1['projection'], outputs2['projection'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # if epoch % 1 == 0:\n",
    "    print(f'Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}')\n",
    "\n",
    "# Save model\n",
    "#torch.save(model.state_dict(), 'gine_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference loop\n",
    "model.eval()\n",
    "all_embeddings = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "   for batch in tqdm(train_loader):  # or test_loader\n",
    "       all_paths.extend(batch[1]) \n",
    "       batch = batch[0].to(device)\n",
    "       outputs = model(batch)\n",
    "       embeddings = outputs['embeddings']\n",
    "       all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "# Concatenate all embeddings\n",
    "final_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "print(f'Extracted {final_embeddings.shape[0]} embeddings of dimension {final_embeddings.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dates = [path.split(\"/\")[-1].split(\"_\")[1] for path in all_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80987d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce20950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Convert embeddings to numpy\n",
    "embeddings_np = final_embeddings.numpy()\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings_np)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], alpha=0.6, hue=graph_dates)\n",
    "#plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.6)\n",
    "plt.title('PCA Visualization')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# plt.scatter(tsne_result[:, 0], tsne_result[:, 1], alpha=0.6)\n",
    "sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], alpha=0.6, hue=graph_dates)\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5de0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9124966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3b6fc3",
   "metadata": {},
   "source": [
    "# Notebook junkyard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-creator-_1ofKhL9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
