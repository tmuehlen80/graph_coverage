{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f802ebec",
   "metadata": {},
   "source": [
    "### Evaluate options for graph embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b72e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "\n",
    "g_path = \"/home/tmuehlen/repos/graph_coverage/actor_graphs/carla/graph_2025-08-23 23:19:38.811319_0_0.pkl\"\n",
    "with open(g_path, \"rb\") as file:\n",
    "    graph = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e244b5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.classes.multidigraph.MultiDiGraph"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d7ebd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef132f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import from_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# This is the GNN architecture you provided\n",
    "class GCNForGraphEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GCNForGraphEmbedding, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1) # Example for a regression task\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. GNN layers to get node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Global Pooling layer to get graph embedding\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. MLP head for final task\n",
    "        x = F.dropout(graph_embedding, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x, graph_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf32f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Create an example NetworkX graph ---\n",
    "G = nx.erdos_renyi_graph(n=15, p=0.3) # 15 nodes, random connections\n",
    "\n",
    "# GNNs need node features. Let's add some random features to each node.\n",
    "# Let's say each node has 5 features.\n",
    "for node in G.nodes():\n",
    "    G.nodes[node]['x'] = np.random.rand(5).tolist() # 'x' is the standard attribute name for features in PyG\n",
    "\n",
    "# --- Step 2: Convert the NetworkX graph to a PyG Data object ---\n",
    "# The from_networkx utility handles the conversion automatically.\n",
    "# It looks for node attributes named 'x' for features and edge attributes named 'edge_attr'.\n",
    "data = from_networkx(G, group_node_attrs=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1894db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyG Data object:\n",
      "Data(edge_index=[2, 62], x=[15, 5])\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"PyG Data object:\")\n",
    "print(data)\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ca3cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNForGraphEmbedding(\n",
       "  (conv1): GCNConv(5, 64)\n",
       "  (conv2): GCNConv(64, 64)\n",
       "  (conv3): GCNConv(64, 64)\n",
       "  (lin): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Step 3: Instantiate the model and run the forward pass ---\n",
    "\n",
    "# Define model parameters\n",
    "num_node_features = data.num_node_features\n",
    "hidden_channels = 64\n",
    "\n",
    "# Instantiate the model\n",
    "model = GCNForGraphEmbedding(num_node_features=num_node_features, \n",
    "                             hidden_channels=hidden_channels)\n",
    "model.eval() # Set model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751bebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction (from MLP head): -0.023900717496871948\n",
      "Shape of the Graph Embedding: torch.Size([1, 64])\n",
      "Graph Embedding Vector:\n",
      "tensor([[-0.2151, -0.0991,  0.0992, -0.1266, -0.0637, -0.0287, -0.1408, -0.1387,\n",
      "         -0.0736,  0.0758,  0.0057,  0.0289,  0.0157, -0.1015, -0.0241,  0.0422,\n",
      "          0.0346, -0.0517, -0.0959,  0.0200, -0.0303,  0.0510,  0.0958, -0.0030,\n",
      "         -0.0386, -0.0098,  0.0141, -0.0939,  0.0014, -0.0446, -0.0390,  0.1108,\n",
      "         -0.0240, -0.1473,  0.0036, -0.0178, -0.0837, -0.0904,  0.1827, -0.0775,\n",
      "          0.0062, -0.0391, -0.0061,  0.1616, -0.0870,  0.0120, -0.0993, -0.0754,\n",
      "         -0.0581,  0.0055, -0.0072,  0.1329, -0.0029, -0.1162,  0.0278,  0.0835,\n",
      "         -0.1292, -0.0088,  0.0805, -0.0362,  0.0530,  0.0900, -0.1261, -0.2070]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The 'batch' vector is needed for pooling. For a single graph, it's a tensor of zeros.\n",
    "# It tells the pooling layer that all nodes belong to the same graph.\n",
    "batch = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "\n",
    "# Get the model output\n",
    "final_output, graph_embedding = model(data.x, data.edge_index, batch)\n",
    "\n",
    "print(f\"Final Prediction (from MLP head): {final_output.item()}\")\n",
    "print(f\"Shape of the Graph Embedding: {graph_embedding.shape}\")\n",
    "print(\"Graph Embedding Vector:\")\n",
    "print(graph_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda0859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acea8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58eea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61960838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2799bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a829199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb952a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GCNForGraphEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(GCNForGraphEmbedding, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 1) # Example for a regression task\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. GNN layers to get node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Global Pooling layer to get graph embedding\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "\n",
    "        # 3. MLP head for final task\n",
    "        x = F.dropout(graph_embedding, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x, graph_embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-creator-_1ofKhL9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
