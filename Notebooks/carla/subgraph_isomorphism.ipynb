{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle\n",
    "from graph_creator.utilities import make_node_edge_df\n",
    "from subgraphs.SubgraphIsomorphismChecker import IsomorphicGrapCoverageCounter\n",
    "from graph_creator.ActorGraph import ActorType\n",
    "from glob import glob\n",
    "\n",
    "os.chdir('../..')\n",
    "print(os.getcwd())\n",
    "\n",
    "# Import subgraph types from the new module\n",
    "from subgraphs.subgraph_types import get_all_subgraphs, get_simple_patterns, get_complex_patterns\n",
    "from subgraphs.SubgraphExtractor import SubgraphExtractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_paths_carla = glob(\"/home/tmuehlen/repos/graph_coverage/actor_graphs/carla_w_intersection/*pkl\")\n",
    "# len(graph_paths_carla)\n",
    "\n",
    "# graph_paths_argo = glob(\"/home/tmuehlen/repos/graph_coverage/actor_graphs/argoverse_nx/*pkl\")\n",
    "# graph_paths_argo = glob(\"/home/tmuehlen/repos/graph_coverage/actor_graphs/argoverse_components_nx/*pkl\")\n",
    "\n",
    "# len(graph_paths_argo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_setting = '1_50_50_10_20_20_4_4_4'\n",
    "carla_graph_dir = f'carla_actor_graph_setting_{graph_setting}'\n",
    "argoverse_graph_dir = f'argoverse_actor_graph_setting_{graph_setting}'\n",
    "\n",
    "\n",
    "carla_components_dir = f\"actor_graphs/{carla_graph_dir}/{carla_graph_dir}_components_nx\"\n",
    "argo_components_dir = f\"actor_graphs/{argoverse_graph_dir}/{argoverse_graph_dir}_components_nx\"\n",
    "\n",
    "graph_paths_carla_components = glob(f\"{carla_components_dir}/*.pkl\")\n",
    "print(f\"Number of Carla component graphs: {len(graph_paths_carla_components)}\")\n",
    "\n",
    "graph_paths_argo_components = glob(f\"{argo_components_dir}/*.pkl\")\n",
    "print(f\"Number of Argoverse component graphs: {len(graph_paths_argo_components)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all subgraph patterns from subgraph_types module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all subgraph patterns from the subgraph_types module\n",
    "coverage_graphs = get_all_subgraphs()\n",
    "\n",
    "print(f\"Total number of subgraph patterns: {len(coverage_graphs)}\")\n",
    "print(f\"\\nSubgraph patterns:\")\n",
    "for name in coverage_graphs.keys():\n",
    "    print(f\"  - {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "isom_cov_counter_carla = IsomorphicGrapCoverageCounter(\n",
    "    coverage_graphs, \n",
    "    graph_paths_carla_components[:], \n",
    "    node_match=[\"actor_type\", \"lane_change\", \"is_on_intersection\"], \n",
    "    edge_match=[\"edge_type\"]\n",
    ")\n",
    "isom_cov_counter_carla.count_isomorphic_graphs()\n",
    "cov_data_df_carla = isom_cov_counter_carla.cov_data_df\n",
    "\n",
    "print(f\"Carla coverage analysis complete!\")\n",
    "print(f\"Shape: {cov_data_df_carla.shape}\")\n",
    "cov_data_df_carla.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isom_cov_counter_argo = IsomorphicGrapCoverageCounter(\n",
    "    coverage_graphs, \n",
    "    graph_paths_argo_components[:], \n",
    "    node_match=[\"actor_type\", \"lane_change\", \"is_on_intersection\"], \n",
    "    edge_match=[\"edge_type\"]\n",
    ")\n",
    "isom_cov_counter_argo.count_isomorphic_graphs()\n",
    "cov_data_df_argo = isom_cov_counter_argo.cov_data_df\n",
    "\n",
    "print(f\"Argoverse coverage analysis complete!\")\n",
    "print(f\"Shape: {cov_data_df_argo.shape}\")\n",
    "cov_data_df_argo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage Metrics Analysis\n",
    "\n",
    "### Definition 1: Absolute Coverage (number of graphs containing each subgraph)\n",
    "### Definition 2: Relative Coverage (percentage of graphs containing each subgraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coverage metrics for both datasets\n",
    "def calculate_coverage_metrics(cov_df, dataset_name):\n",
    "    \"\"\"Calculate both absolute and relative coverage metrics.\"\"\"\n",
    "    subgraph_cols = [col for col in cov_df.columns if col not in ['degree', 'density', 'diameter', 'path']]\n",
    "    \n",
    "    # Absolute coverage: count of graphs containing each subgraph\n",
    "    absolute_coverage = cov_df[subgraph_cols].sum()\n",
    "    \n",
    "    # Relative coverage: percentage of graphs containing each subgraph\n",
    "    relative_coverage = (cov_df[subgraph_cols].sum() / len(cov_df)) * 100\n",
    "    \n",
    "    # Combine into a dataframe\n",
    "    coverage_df = pd.DataFrame({\n",
    "        'subgraph': subgraph_cols,\n",
    "        'absolute_count': absolute_coverage.values,\n",
    "        'relative_percentage': relative_coverage.values\n",
    "    })\n",
    "    coverage_df = coverage_df.sort_values('absolute_count', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Coverage Metrics for {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total graphs analyzed: {len(cov_df)}\")\n",
    "    print(f\"\\nTop 10 most covered subgraphs:\")\n",
    "    print(coverage_df.head(10).to_string(index=False))\n",
    "    print(f\"\\nBottom 10 least covered subgraphs:\")\n",
    "    print(coverage_df.tail(10).to_string(index=False))\n",
    "    \n",
    "    return coverage_df\n",
    "\n",
    "# Calculate metrics for both datasets\n",
    "coverage_carla = calculate_coverage_metrics(cov_data_df_carla, \"CARLA\")\n",
    "coverage_argo = calculate_coverage_metrics(cov_data_df_argo, \"ARGOVERSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis: Identify Differences Between Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare coverage between datasets\n",
    "comparison_df = pd.merge(\n",
    "    coverage_carla[['subgraph', 'absolute_count', 'relative_percentage']],\n",
    "    coverage_argo[['subgraph', 'absolute_count', 'relative_percentage']],\n",
    "    on='subgraph',\n",
    "    suffixes=('_carla', '_argo')\n",
    ")\n",
    "\n",
    "# Calculate differences\n",
    "comparison_df['abs_diff'] = comparison_df['absolute_count_carla'] - comparison_df['absolute_count_argo']\n",
    "comparison_df['rel_diff'] = comparison_df['relative_percentage_carla'] - comparison_df['relative_percentage_argo']\n",
    "\n",
    "# Identify holes: subgraphs missing or very rare in one dataset\n",
    "threshold_rare = 1.0  # Less than 1% coverage\n",
    "comparison_df['hole_in_carla'] = comparison_df['relative_percentage_carla'] < threshold_rare\n",
    "comparison_df['hole_in_argo'] = comparison_df['relative_percentage_argo'] < threshold_rare\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COVERAGE COMPARISON: CARLA vs ARGOVERSE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Subgraphs with LARGEST DIFFERENCES (sorted by relative difference):\")\n",
    "print(comparison_df.sort_values('rel_diff', key=abs, ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n2. HOLES IN CARLA (subgraphs rare or missing in Carla but present in Argoverse):\")\n",
    "holes_carla = comparison_df[comparison_df['hole_in_carla'] & ~comparison_df['hole_in_argo']]\n",
    "if len(holes_carla) > 0:\n",
    "    print(holes_carla[['subgraph', 'relative_percentage_carla', 'relative_percentage_argo']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No significant holes found in Carla dataset\")\n",
    "\n",
    "print(\"\\n3. HOLES IN ARGOVERSE (subgraphs rare or missing in Argoverse but present in Carla):\")\n",
    "holes_argo = comparison_df[comparison_df['hole_in_argo'] & ~comparison_df['hole_in_carla']]\n",
    "if len(holes_argo) > 0:\n",
    "    print(holes_argo[['subgraph', 'relative_percentage_carla', 'relative_percentage_argo']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No significant holes found in Argoverse dataset\")\n",
    "\n",
    "print(\"\\n4. COMMON HOLES (subgraphs rare or missing in BOTH datasets):\")\n",
    "common_holes = comparison_df[comparison_df['hole_in_carla'] & comparison_df['hole_in_argo']]\n",
    "if len(common_holes) > 0:\n",
    "    print(common_holes[['subgraph', 'relative_percentage_carla', 'relative_percentage_argo']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No common holes found\")\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Coverage Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side bar chart comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Sort by Carla coverage for consistent ordering\n",
    "comparison_sorted = comparison_df.sort_values('relative_percentage_carla', ascending=True)\n",
    "\n",
    "# Carla coverage\n",
    "axes[0].barh(comparison_sorted['subgraph'], comparison_sorted['relative_percentage_carla'], \n",
    "             color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Coverage (%)', fontsize=12)\n",
    "axes[0].set_title('CARLA Dataset Coverage', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Argoverse coverage\n",
    "axes[1].barh(comparison_sorted['subgraph'], comparison_sorted['relative_percentage_argo'], \n",
    "             color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Coverage (%)', fontsize=12)\n",
    "axes[1].set_title('ARGOVERSE Dataset Coverage', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/coverage_comparison_side_by_side.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dual-axis chart showing coverage percentages and differences\n",
    "fig, ax1 = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Sort by average coverage for better visualization\n",
    "comparison_sorted = comparison_df.copy()\n",
    "comparison_sorted['avg_coverage'] = (comparison_sorted['relative_percentage_carla'] + comparison_sorted['relative_percentage_argo']) / 2\n",
    "comparison_sorted = comparison_sorted.sort_values('avg_coverage', ascending=True)\n",
    "\n",
    "x_pos = np.arange(len(comparison_sorted))\n",
    "width = 0.35\n",
    "\n",
    "# Left y-axis: Coverage percentages\n",
    "ax1.barh(x_pos - width/2, comparison_sorted['relative_percentage_carla'], \n",
    "         width, label='CARLA Coverage', color='skyblue', alpha=0.8)\n",
    "ax1.barh(x_pos + width/2, comparison_sorted['relative_percentage_argo'], \n",
    "         width, label='Argoverse Coverage', color='coral', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Coverage (%)', fontsize=12)\n",
    "ax1.set_ylabel('Subgraph Pattern', fontsize=12)\n",
    "ax1.set_yticks(x_pos)\n",
    "ax1.set_yticklabels(comparison_sorted['subgraph'], fontsize=9)\n",
    "ax1.tick_params(axis='y', labelsize=9)\n",
    "ax1.legend(loc='upper left', fontsize=10)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Right y-axis: Difference\n",
    "ax2 = ax1.twiny()\n",
    "colors = ['green' if x > 0 else 'red' for x in comparison_sorted['rel_diff']]\n",
    "ax2.scatter(comparison_sorted['rel_diff'], x_pos, \n",
    "           c=colors, s=100, alpha=0.6, marker='D', \n",
    "           label='Difference (C-A)', edgecolors='black', linewidths=1)\n",
    "\n",
    "# Add vertical line at zero for difference\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "ax2.set_xlabel('Coverage Difference (CARLA - Argoverse) %', fontsize=12)\n",
    "ax2.legend(loc='upper right', fontsize=10)\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle=':', color='gray')\n",
    "\n",
    "plt.title('Dataset Coverage Comparison: Percentages and Differences\\n(Green = More in CARLA, Red = More in Argoverse)', \n",
    "         fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/coverage_comparison_dual_axis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar charts for absolute coverage counts\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Carla bar chart\n",
    "barchart_df_carla = cov_data_df_carla[coverage_graphs.keys()].sum().reset_index().rename(columns={\"index\":\"scenario\", 0: \"count\"})\n",
    "barchart_df_carla = barchart_df_carla.sort_values('count', ascending=False)\n",
    "axes[0].bar(range(len(barchart_df_carla)), barchart_df_carla['count'], \n",
    "            color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xticks(range(len(barchart_df_carla)))\n",
    "axes[0].set_xticklabels(barchart_df_carla['scenario'], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('CARLA: Subgraph Coverage (Absolute Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Argoverse bar chart\n",
    "barchart_df_argo = cov_data_df_argo[coverage_graphs.keys()].sum().reset_index().rename(columns={\"index\":\"scenario\", 0: \"count\"})\n",
    "barchart_df_argo = barchart_df_argo.sort_values('count', ascending=False)\n",
    "axes[1].bar(range(len(barchart_df_argo)), barchart_df_argo['count'], \n",
    "            color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xticks(range(len(barchart_df_argo)))\n",
    "axes[1].set_xticklabels(barchart_df_argo['scenario'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('ARGOVERSE: Subgraph Coverage (Absolute Counts)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/subgraph_coverage_barcharts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Dive: Speed and Path Analysis Per Scenario\n",
    "\n",
    "### Analyze speed distributions and driven paths for each subgraph type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scenario_data_with_roles(cov_df, scenario_name, scenario_pattern, node_match_attrs, edge_match_attrs, max_samples=500):\n",
    "    \"\"\"\n",
    "    Extract node and edge data with role information (a, b, c, etc.) for each actor.\n",
    "    Role is determined by isomorphism mapping to the subgraph pattern.\n",
    "    \"\"\"\n",
    "    scenario_graph_paths = cov_df[cov_df[scenario_name]].path.to_list()\n",
    "    \n",
    "    if len(scenario_graph_paths) > max_samples:\n",
    "        scenario_graph_paths = random.sample(scenario_graph_paths, max_samples)\n",
    "    \n",
    "    node_dfs = []\n",
    "    edge_dfs = []\n",
    "    \n",
    "    for graph_path in tqdm(scenario_graph_paths, desc=f\"Loading {scenario_name}\"):\n",
    "        try:\n",
    "            with open(graph_path, \"rb\") as file:\n",
    "                ag_nx = pickle.load(file)\n",
    "            \n",
    "            GM = nx.algorithms.isomorphism.DiGraphMatcher(\n",
    "                ag_nx, scenario_pattern,\n",
    "                node_match=nx.algorithms.isomorphism.categorical_node_match(node_match_attrs, [None] * len(node_match_attrs)),\n",
    "                edge_match=nx.algorithms.isomorphism.categorical_edge_match(edge_match_attrs, [None] * len(edge_match_attrs))\n",
    "            )\n",
    "            \n",
    "            mapping = None\n",
    "            for m in GM.subgraph_isomorphisms_iter():\n",
    "                mapping = m\n",
    "                break\n",
    "            \n",
    "            if mapping is None:\n",
    "                continue\n",
    "            \n",
    "            node_to_role = {main_node: pattern_node for main_node, pattern_node in mapping.items()}\n",
    "            node_df, edge_df = make_node_edge_df(ag_nx)\n",
    "            \n",
    "            node_df[\"role\"] = node_df[\"node_id\"].map(node_to_role)\n",
    "            node_df[\"role\"] = node_df[\"role\"].fillna(\"other\")\n",
    "            \n",
    "            node_df[\"path\"] = graph_path\n",
    "            edge_df[\"path\"] = graph_path\n",
    "            node_df[\"scenario\"] = scenario_name\n",
    "            edge_df[\"scenario\"] = scenario_name\n",
    "            \n",
    "            node_dfs.append(node_df)\n",
    "            edge_dfs.append(edge_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {graph_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(node_dfs) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    return pd.concat(node_dfs, ignore_index=True), pd.concat(edge_dfs, ignore_index=True)\n",
    "\n",
    "print(\"Helper function with role tracking defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top scenarios for detailed analysis (those with sufficient coverage)\n",
    "top_scenarios_carla = coverage_carla[coverage_carla['relative_percentage'] >= 5.0]['subgraph'].head(10).tolist()\n",
    "top_scenarios_argo = coverage_argo[coverage_argo['relative_percentage'] >= 5.0]['subgraph'].head(10).tolist()\n",
    "\n",
    "print(f\"Top scenarios for CARLA analysis: {len(top_scenarios_carla)}\")\n",
    "print(f\"Top scenarios for ARGOVERSE analysis: {len(top_scenarios_argo)}\")\n",
    "\n",
    "node_match_attrs = [\"actor_type\", \"lane_change\", \"is_on_intersection\"]\n",
    "edge_match_attrs = [\"edge_type\"]\n",
    "\n",
    "print(\"\\nExtracting CARLA scenario data...\")\n",
    "carla_scenario_nodes = []\n",
    "carla_scenario_edges = []\n",
    "\n",
    "for scenario in top_scenarios_carla[:5]:\n",
    "    scenario_pattern = coverage_graphs[scenario]\n",
    "    node_df, edge_df = extract_scenario_data_with_roles(\n",
    "        cov_data_df_carla, scenario, scenario_pattern, \n",
    "        node_match_attrs, edge_match_attrs, max_samples=300\n",
    "    )\n",
    "    if node_df is not None:\n",
    "        carla_scenario_nodes.append(node_df)\n",
    "        carla_scenario_edges.append(edge_df)\n",
    "\n",
    "if len(carla_scenario_nodes) > 0:\n",
    "    carla_all_nodes = pd.concat(carla_scenario_nodes, ignore_index=True)\n",
    "    carla_all_edges = pd.concat(carla_scenario_edges, ignore_index=True)\n",
    "    print(f\"Carla nodes: {len(carla_all_nodes)}, edges: {len(carla_all_edges)}\")\n",
    "else:\n",
    "    print(\"No Carla scenario data extracted\")\n",
    "\n",
    "print(\"\\nExtracting ARGOVERSE scenario data...\")\n",
    "argo_scenario_nodes = []\n",
    "argo_scenario_edges = []\n",
    "\n",
    "for scenario in top_scenarios_argo[:5]:\n",
    "    scenario_pattern = coverage_graphs[scenario]\n",
    "    node_df, edge_df = extract_scenario_data_with_roles(\n",
    "        cov_data_df_argo, scenario, scenario_pattern,\n",
    "        node_match_attrs, edge_match_attrs, max_samples=300\n",
    "    )\n",
    "    if node_df is not None:\n",
    "        argo_scenario_nodes.append(node_df)\n",
    "        argo_scenario_edges.append(edge_df)\n",
    "\n",
    "if len(argo_scenario_nodes) > 0:\n",
    "    argo_all_nodes = pd.concat(argo_scenario_nodes, ignore_index=True)\n",
    "    argo_all_edges = pd.concat(argo_scenario_edges, ignore_index=True)\n",
    "    print(f\"Argo nodes: {len(argo_all_nodes)}, edges: {len(argo_all_edges)}\")\n",
    "else:\n",
    "    print(\"No Argoverse scenario data extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed distribution analysis per scenario - CARLA\n",
    "if len(carla_scenario_nodes) > 0:\n",
    "    n_scenarios = len(carla_scenario_nodes)\n",
    "    fig, axes = plt.subplots(n_scenarios, 2, figsize=(14, 4*n_scenarios))\n",
    "    \n",
    "    if n_scenarios == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (node_df, edge_df) in enumerate(zip(carla_scenario_nodes, carla_scenario_edges)):\n",
    "        scenario_name = node_df['scenario'].iloc[0]\n",
    "        \n",
    "        # Speed distribution\n",
    "        axes[idx, 0].hist(node_df['lon_speed'], bins=30, color='skyblue', \n",
    "                         edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 0].set_xlabel('Longitudinal Speed (m/s)', fontsize=10)\n",
    "        axes[idx, 0].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[idx, 0].set_title(f'Speed Distribution\\n{scenario_name}', \n",
    "                               fontsize=11, fontweight='bold')\n",
    "        axes[idx, 0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Path length distribution\n",
    "        axes[idx, 1].hist(edge_df['path_length'], bins=30, color='coral', \n",
    "                         edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 1].set_xlabel('Path Length (m)', fontsize=10)\n",
    "        axes[idx, 1].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[idx, 1].set_title(f'Path Length Distribution\\n{scenario_name}', \n",
    "                               fontsize=11, fontweight='bold')\n",
    "        axes[idx, 1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.suptitle('CARLA: Speed and Path Distributions by Scenario', \n",
    "                 fontsize=16, fontweight='bold', y=1.001)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/carla_speed_path_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Carla scenario data to plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why are there negative paths length? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed distribution analysis per scenario - ARGOVERSE\n",
    "if len(argo_scenario_nodes) > 0:\n",
    "    n_scenarios = len(argo_scenario_nodes)\n",
    "    fig, axes = plt.subplots(n_scenarios, 2, figsize=(14, 4*n_scenarios))\n",
    "    \n",
    "    if n_scenarios == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (node_df, edge_df) in enumerate(zip(argo_scenario_nodes, argo_scenario_edges)):\n",
    "        scenario_name = node_df['scenario'].iloc[0]\n",
    "        \n",
    "        # Speed distribution\n",
    "        axes[idx, 0].hist(node_df['lon_speed'], bins=30, color='skyblue', \n",
    "                         edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 0].set_xlabel('Longitudinal Speed (m/s)', fontsize=10)\n",
    "        axes[idx, 0].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[idx, 0].set_title(f'Speed Distribution\\n{scenario_name}', \n",
    "                               fontsize=11, fontweight='bold')\n",
    "        axes[idx, 0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        # Path length distribution\n",
    "        axes[idx, 1].hist(edge_df['path_length'], bins=30, color='coral', \n",
    "                         edgecolor='black', alpha=0.7)\n",
    "        axes[idx, 1].set_xlabel('Path Length (m)', fontsize=10)\n",
    "        axes[idx, 1].set_ylabel('Frequency', fontsize=10)\n",
    "        axes[idx, 1].set_title(f'Path Length Distribution\\n{scenario_name}', \n",
    "                               fontsize=11, fontweight='bold')\n",
    "        axes[idx, 1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.suptitle('ARGOVERSE: Speed and Path Distributions by Scenario', \n",
    "                 fontsize=16, fontweight='bold', y=1.001)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plots/argo_speed_path_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No Argoverse scenario data to plot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis of speed distributions\n",
    "print(\"SPEED DISTRIBUTION COMPARISON: Identifying Coverage Holes\")\n",
    "\n",
    "if len(carla_scenario_nodes) > 0 and len(argo_scenario_nodes) > 0:\n",
    "    # Compare overlapping scenarios\n",
    "    common_scenarios = set([df['scenario'].iloc[0] for df in carla_scenario_nodes]) & \\\n",
    "                      set([df['scenario'].iloc[0] for df in argo_scenario_nodes])\n",
    "    \n",
    "    print(f\"\\nNumber of common scenarios for comparison: {len(common_scenarios)}\")\n",
    "    \n",
    "    for scenario in common_scenarios:\n",
    "        # Get data for this scenario\n",
    "        carla_data = [df for df in carla_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "        argo_data = [df for df in argo_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scenario: {scenario}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Speed analysis\n",
    "        carla_speeds = carla_data['lon_speed'].dropna()\n",
    "        argo_speeds = argo_data['lon_speed'].dropna()\n",
    "        \n",
    "        print(f\"\\nSpeed Distribution:\")\n",
    "        print(f\"  CARLA: mean={carla_speeds.mean():.2f}, std={carla_speeds.std():.2f}, \"\n",
    "              f\"min={carla_speeds.min():.2f}, max={carla_speeds.max():.2f}\")\n",
    "        print(f\"  ARGO:  mean={argo_speeds.mean():.2f}, std={argo_speeds.std():.2f}, \"\n",
    "              f\"min={argo_speeds.min():.2f}, max={argo_speeds.max():.2f}\")\n",
    "        \n",
    "        # Identify speed holes (ranges present in one but not the other)\n",
    "        speed_bins = np.linspace(\n",
    "            min(carla_speeds.min(), argo_speeds.min()),\n",
    "            max(carla_speeds.max(), argo_speeds.max()),\n",
    "            20\n",
    "        )\n",
    "        \n",
    "        carla_hist, _ = np.histogram(carla_speeds, bins=speed_bins)\n",
    "        argo_hist, _ = np.histogram(argo_speeds, bins=speed_bins)\n",
    "        \n",
    "        # Find bins with significant coverage in one but not the other\n",
    "        threshold = 0.01  # 1% of max count\n",
    "        carla_threshold = threshold * carla_hist.max()\n",
    "        argo_threshold = threshold * argo_hist.max()\n",
    "        \n",
    "        holes_in_carla = np.where((argo_hist > argo_threshold) & (carla_hist < carla_threshold))[0]\n",
    "        holes_in_argo = np.where((carla_hist > carla_threshold) & (argo_hist < argo_threshold))[0]\n",
    "        \n",
    "        if len(holes_in_carla) > 0:\n",
    "            print(f\"\\n  Speed HOLES in CARLA (present in Argo):\")\n",
    "            for idx in holes_in_carla:\n",
    "                print(f\"    Range: [{speed_bins[idx]:.1f}, {speed_bins[idx+1]:.1f}] m/s\")\n",
    "        \n",
    "        if len(holes_in_argo) > 0:\n",
    "            print(f\"\\n  Speed HOLES in ARGOVERSE (present in Carla):\")\n",
    "            for idx in holes_in_argo:\n",
    "                print(f\"    Range: [{speed_bins[idx]:.1f}, {speed_bins[idx+1]:.1f}] m/s\")\n",
    "        \n",
    "        if len(holes_in_carla) == 0 and len(holes_in_argo) == 0:\n",
    "            print(f\"\\n  No significant speed coverage holes detected\")\n",
    "else:\n",
    "    print(\"\\nInsufficient data for comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative analysis of path length distributions\n",
    "print(\"=\"*80)\n",
    "print(\"PATH LENGTH DISTRIBUTION COMPARISON: Identifying Coverage Holes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(carla_scenario_edges) > 0 and len(argo_scenario_edges) > 0:\n",
    "    # Compare overlapping scenarios\n",
    "    common_scenarios = set([df['scenario'].iloc[0] for df in carla_scenario_edges]) & \\\n",
    "                      set([df['scenario'].iloc[0] for df in argo_scenario_edges])\n",
    "    \n",
    "    print(f\"\\nNumber of common scenarios for comparison: {len(common_scenarios)}\")\n",
    "    \n",
    "    for scenario in common_scenarios:\n",
    "        # Get data for this scenario\n",
    "        carla_data = [df for df in carla_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "        argo_data = [df for df in argo_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scenario: {scenario}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Path length analysis\n",
    "        carla_paths = carla_data['path_length'].dropna()\n",
    "        argo_paths = argo_data['path_length'].dropna()\n",
    "        \n",
    "        print(f\"\\nPath Length Distribution:\")\n",
    "        print(f\"  CARLA: mean={carla_paths.mean():.2f}, std={carla_paths.std():.2f}, \"\n",
    "              f\"min={carla_paths.min():.2f}, max={carla_paths.max():.2f}\")\n",
    "        print(f\"  ARGO:  mean={argo_paths.mean():.2f}, std={argo_paths.std():.2f}, \"\n",
    "              f\"min={argo_paths.min():.2f}, max={argo_paths.max():.2f}\")\n",
    "        \n",
    "        # Identify path length holes\n",
    "        path_bins = np.linspace(\n",
    "            min(carla_paths.min(), argo_paths.min()),\n",
    "            max(carla_paths.max(), argo_paths.max()),\n",
    "            20\n",
    "        )\n",
    "        \n",
    "        carla_hist, _ = np.histogram(carla_paths, bins=path_bins)\n",
    "        argo_hist, _ = np.histogram(argo_paths, bins=path_bins)\n",
    "        \n",
    "        threshold = 0.01\n",
    "        carla_threshold = threshold * carla_hist.max()\n",
    "        argo_threshold = threshold * argo_hist.max()\n",
    "        \n",
    "        holes_in_carla = np.where((argo_hist > argo_threshold) & (carla_hist < carla_threshold))[0]\n",
    "        holes_in_argo = np.where((carla_hist > carla_threshold) & (argo_hist < argo_threshold))[0]\n",
    "        \n",
    "        if len(holes_in_carla) > 0:\n",
    "            print(f\"\\n  Path Length HOLES in CARLA (present in Argo):\")\n",
    "            for idx in holes_in_carla:\n",
    "                print(f\"    Range: [{path_bins[idx]:.1f}, {path_bins[idx+1]:.1f}] m\")\n",
    "        \n",
    "        if len(holes_in_argo) > 0:\n",
    "            print(f\"\\n  Path Length HOLES in ARGOVERSE (present in Carla):\")\n",
    "            for idx in holes_in_argo:\n",
    "                print(f\"    Range: [{path_bins[idx]:.1f}, {path_bins[idx+1]:.1f}] m\")\n",
    "        \n",
    "        if len(holes_in_carla) == 0 and len(holes_in_argo) == 0:\n",
    "            print(f\"\\n  No significant path length coverage holes detected\")\n",
    "else:\n",
    "    print(\"\\nInsufficient data for comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize speed distributions BY ROLE for common scenarios with hole highlighting\n",
    "if len(carla_scenario_nodes) > 0 and len(argo_scenario_nodes) > 0:\n",
    "    common_scenarios = list(set([df['scenario'].iloc[0] for df in carla_scenario_nodes]) & \n",
    "                           set([df['scenario'].iloc[0] for df in argo_scenario_nodes]))\n",
    "    \n",
    "    if len(common_scenarios) > 0:\n",
    "        # Limit to first 2 scenarios for readability (since we'll have multiple roles per scenario)\n",
    "        n_scenarios = min(len(common_scenarios), 2)\n",
    "        \n",
    "        for scenario in common_scenarios[:n_scenarios]:\n",
    "            # Get data for this scenario\n",
    "            carla_node_data = [df for df in carla_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "            argo_node_data = [df for df in argo_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "            \n",
    "            # Get all roles in this subgraph pattern (excluding 'other')\n",
    "            all_roles = sorted([r for r in carla_node_data['role'].unique() if r != 'other'])\n",
    "            \n",
    "            if len(all_roles) == 0:\n",
    "                print(f\"No roles found for scenario {scenario}\")\n",
    "                continue\n",
    "            \n",
    "            # Create subplot grid: rows = roles, cols = speed (left) and path (right)\n",
    "            n_roles = len(all_roles)\n",
    "            fig, axes = plt.subplots(n_roles, 2, figsize=(16, 4*n_roles))\n",
    "            \n",
    "            # Handle single role case\n",
    "            if n_roles == 1:\n",
    "                axes = axes.reshape(1, -1)\n",
    "            \n",
    "            for role_idx, role in enumerate(all_roles):\n",
    "                # Filter data for this specific role\n",
    "                carla_role_data = carla_node_data[carla_node_data['role'] == role]\n",
    "                argo_role_data = argo_node_data[argo_node_data['role'] == role]\n",
    "                \n",
    "                # === SPEED COMPARISON FOR THIS ROLE ===\n",
    "                # Filter out low speeds (< 2 m/s)\n",
    "                carla_speed = carla_role_data[carla_role_data['lon_speed'] >= 2.0]['lon_speed']\n",
    "                argo_speed = argo_role_data[argo_role_data['lon_speed'] >= 2.0]['lon_speed']\n",
    "                \n",
    "                if len(carla_speed) == 0 or len(argo_speed) == 0:\n",
    "                    axes[role_idx, 0].text(0.5, 0.5, f'Insufficient data for role \"{role}\"', \n",
    "                                          ha='center', va='center', fontsize=12)\n",
    "                    axes[role_idx, 0].set_xlim(0, 1)\n",
    "                    axes[role_idx, 0].set_ylim(0, 1)\n",
    "                    axes[role_idx, 0].axis('off')\n",
    "                else:\n",
    "                    # Use fixed bins: start at 2.0, step by 1.0 m/s\n",
    "                    combined_max = max(carla_speed.max(), argo_speed.max())\n",
    "                    bin_edges_speed = np.arange(2.0, combined_max + 1.0, 1.0)  # Fixed 1.0 m/s bins\n",
    "                    combined_min = 2.0\n",
    "                    \n",
    "                    # Calculate histograms using the same bins\n",
    "                    argo_hist, _ = np.histogram(argo_speed, bins=bin_edges_speed, density=True)\n",
    "                    carla_hist, _ = np.histogram(carla_speed, bins=bin_edges_speed, density=True)\n",
    "                    \n",
    "                    # Plot histograms using the same bin edges (density=True means each integrates to 1)\n",
    "                    axes[role_idx, 0].hist(carla_speed, bins=bin_edges_speed, alpha=0.6, \n",
    "                                          label=f'CARLA (n={len(carla_speed)})', color='skyblue', density=True)\n",
    "                    axes[role_idx, 0].hist(argo_speed, bins=bin_edges_speed, alpha=0.6, \n",
    "                                          label=f'Argoverse (n={len(argo_speed)})', color='coral', density=True)\n",
    "                    \n",
    "                    # Get y-limits AFTER both histograms are plotted\n",
    "                    axes[role_idx, 0].set_xlim(combined_min, combined_max)\n",
    "                    ylim = axes[role_idx, 0].get_ylim()\n",
    "                    y_middle = ylim[1] * 0.5\n",
    "                    rect_height = ylim[1] * 0.08\n",
    "                    \n",
    "                    # Define thresholds for hole detection\n",
    "                    # High threshold: Argoverse has meaningful data (absolute density value)\n",
    "                    high_threshold = 0.01  # Minimum density to consider Argo has data\n",
    "                    # Low threshold: CARLA has very little data (relative comparison)\n",
    "                    # Mark as hole if CARLA has less than 10% of what Argoverse has\n",
    "                    \n",
    "                    # Mark each bin where Argo is high AND CARLA is low (coverage holes)\n",
    "                    hole_added = False\n",
    "                    for i in range(len(bin_edges_speed) - 1):  # Iterate through bins\n",
    "                        # Check if this bin is a hole:\n",
    "                        # 1. Argoverse has meaningful data (> threshold)\n",
    "                        # 2. CARLA has much less (< 10% of Argo's density)\n",
    "                        if argo_hist[i] >= high_threshold and carla_hist[i] < (argo_hist[i] * 0.1):\n",
    "                            x_start = bin_edges_speed[i]\n",
    "                            bin_width = bin_edges_speed[i+1] - bin_edges_speed[i]\n",
    "                            \n",
    "                            if not hole_added:\n",
    "                                axes[role_idx, 0].add_patch(plt.Rectangle((x_start, y_middle - rect_height/2),\n",
    "                                                                         bin_width, rect_height,\n",
    "                                                                         facecolor='green', edgecolor='darkgreen',\n",
    "                                                                         alpha=0.7, linewidth=2,\n",
    "                                                                         label='CARLA Hole', zorder=10))\n",
    "                                hole_added = True\n",
    "                            else:\n",
    "                                axes[role_idx, 0].add_patch(plt.Rectangle((x_start, y_middle - rect_height/2),\n",
    "                                                                         bin_width, rect_height,\n",
    "                                                                         facecolor='green', edgecolor='darkgreen',\n",
    "                                                                         alpha=0.7, linewidth=2, zorder=10))\n",
    "                    \n",
    "                    axes[role_idx, 0].set_xlabel('Longitudinal Speed (m/s)', fontsize=10)\n",
    "                    axes[role_idx, 0].set_ylabel('Density', fontsize=10)\n",
    "                    axes[role_idx, 0].set_title(f'Speed Comparison - Role \"{role}\" (v >= 2 m/s)', \n",
    "                                               fontsize=11, fontweight='bold')\n",
    "                    axes[role_idx, 0].legend(loc='best', fontsize=9)\n",
    "                    axes[role_idx, 0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "                \n",
    "                # === PATH LENGTH COMPARISON FOR THIS ROLE ===\n",
    "                # Get edge data involving this role (edges where source or target is this role)\n",
    "                carla_role_node_ids = carla_role_data['node_id'].tolist()\n",
    "                argo_role_node_ids = argo_role_data['node_id'].tolist()\n",
    "                \n",
    "                # Get corresponding edge data from the scenario edges\n",
    "                carla_edge_data = [df for df in carla_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "                argo_edge_data = [df for df in argo_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "                \n",
    "                # Filter edges where source node has this role\n",
    "                carla_role_edges = carla_edge_data[carla_edge_data['source'].isin(carla_role_node_ids)]\n",
    "                argo_role_edges = argo_edge_data[argo_edge_data['source'].isin(argo_role_node_ids)]\n",
    "                \n",
    "                if len(carla_role_edges) == 0 or len(argo_role_edges) == 0:\n",
    "                    axes[role_idx, 1].text(0.5, 0.5, f'Insufficient edge data for role \"{role}\"', \n",
    "                                          ha='center', va='center', fontsize=12)\n",
    "                    axes[role_idx, 1].set_xlim(0, 1)\n",
    "                    axes[role_idx, 1].set_ylim(0, 1)\n",
    "                    axes[role_idx, 1].axis('off')\n",
    "                else:\n",
    "                    # Use fixed bins: step by 5.0 meters for path length\n",
    "                    combined_min_path = 0.0\n",
    "                    combined_max_path = max(carla_role_edges['path_length'].max(), argo_role_edges['path_length'].max())\n",
    "                    bin_edges_path = np.arange(0.0, combined_max_path + 5.0, 5.0)  # Fixed 5.0 m bins\n",
    "                    \n",
    "                    # Calculate histograms using the same bins\n",
    "                    argo_hist_path, _ = np.histogram(argo_role_edges['path_length'], bins=bin_edges_path, density=True)\n",
    "                    carla_hist_path, _ = np.histogram(carla_role_edges['path_length'], bins=bin_edges_path, density=True)\n",
    "                    \n",
    "                    # Plot histograms using the same bin edges (density=True means each integrates to 1)\n",
    "                    axes[role_idx, 1].hist(carla_role_edges['path_length'], bins=bin_edges_path, alpha=0.6, \n",
    "                                          label=f'CARLA (n={len(carla_role_edges)})', color='skyblue', density=True)\n",
    "                    axes[role_idx, 1].hist(argo_role_edges['path_length'], bins=bin_edges_path, alpha=0.6, \n",
    "                                          label=f'Argoverse (n={len(argo_role_edges)})', color='coral', density=True)\n",
    "                    \n",
    "                    # Get y-limits AFTER both histograms are plotted\n",
    "                    axes[role_idx, 1].set_xlim(combined_min_path, combined_max_path)\n",
    "                    ylim_path = axes[role_idx, 1].get_ylim()\n",
    "                    y_middle_path = ylim_path[1] * 0.5\n",
    "                    rect_height_path = ylim_path[1] * 0.08\n",
    "                    \n",
    "                    # Define thresholds for hole detection\n",
    "                    # High threshold: Argoverse has meaningful data (absolute density value)\n",
    "                    high_threshold_path = 0.01  # Minimum density to consider Argo has data\n",
    "                    # Mark as hole if CARLA has less than 10% of what Argoverse has\n",
    "                    \n",
    "                    # Mark each bin where Argo is high AND CARLA is low (coverage holes)\n",
    "                    hole_added_path = False\n",
    "                    for i in range(len(bin_edges_path) - 1):  # Iterate through bins\n",
    "                        # Check if this bin is a hole:\n",
    "                        # 1. Argoverse has meaningful data (> threshold)\n",
    "                        # 2. CARLA has much less (< 10% of Argo's density)\n",
    "                        if argo_hist_path[i] >= high_threshold_path and carla_hist_path[i] < (argo_hist_path[i] * 0.1):\n",
    "                            x_start_path = bin_edges_path[i]\n",
    "                            bin_width_path = bin_edges_path[i+1] - bin_edges_path[i]\n",
    "                            \n",
    "                            if not hole_added_path:\n",
    "                                axes[role_idx, 1].add_patch(plt.Rectangle((x_start_path, y_middle_path - rect_height_path/2),\n",
    "                                                                         bin_width_path, rect_height_path,\n",
    "                                                                         facecolor='green', edgecolor='darkgreen',\n",
    "                                                                         alpha=0.7, linewidth=2,\n",
    "                                                                         label='CARLA Hole', zorder=10))\n",
    "                                hole_added_path = True\n",
    "                            else:\n",
    "                                axes[role_idx, 1].add_patch(plt.Rectangle((x_start_path, y_middle_path - rect_height_path/2),\n",
    "                                                                         bin_width_path, rect_height_path,\n",
    "                                                                         facecolor='green', edgecolor='darkgreen',\n",
    "                                                                         alpha=0.7, linewidth=2, zorder=10))\n",
    "                    \n",
    "                    axes[role_idx, 1].set_xlabel('Path Length (m)', fontsize=10)\n",
    "                    axes[role_idx, 1].set_ylabel('Density', fontsize=10)\n",
    "                    axes[role_idx, 1].set_title(f'Path Length Comparison - Role \"{role}\"', \n",
    "                                               fontsize=11, fontweight='bold')\n",
    "                    axes[role_idx, 1].legend(loc='best', fontsize=9)\n",
    "                    axes[role_idx, 1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "            \n",
    "            plt.suptitle(f'Role-Specific Distribution Comparison: {scenario}\\n(Green rectangles = CARLA coverage holes)', \n",
    "                         fontsize=14, fontweight='bold', y=0.995)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'plots/role_comparison_{scenario.replace(\"/\", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No common scenarios for visualization\")\n",
    "else:\n",
    "    print(\"Insufficient data for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Speed/Path Distribution Holes to CSV\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"2. Exporting speed and path distribution holes...\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "speed_holes_data = []\n",
    "path_holes_data = []\n",
    "\n",
    "if len(carla_scenario_nodes) > 0 and len(argo_scenario_nodes) > 0:\n",
    "    common_scenarios = list(set([df['scenario'].iloc[0] for df in carla_scenario_nodes]) & \n",
    "                           set([df['scenario'].iloc[0] for df in argo_scenario_nodes]))\n",
    "    \n",
    "    for scenario in common_scenarios:\n",
    "        print(f\"  Processing scenario: {scenario}\")\n",
    "        \n",
    "        # Get data for this scenario\n",
    "        carla_node_data = [df for df in carla_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "        argo_node_data = [df for df in argo_scenario_nodes if df['scenario'].iloc[0] == scenario][0]\n",
    "        \n",
    "        # Get all roles\n",
    "        all_roles = sorted([r for r in carla_node_data['role'].unique() if r != 'other'])\n",
    "        \n",
    "        for role in all_roles:\n",
    "            # === SPEED HOLES ===\n",
    "            carla_role_data = carla_node_data[carla_node_data['role'] == role]\n",
    "            argo_role_data = argo_node_data[argo_node_data['role'] == role]\n",
    "            \n",
    "            carla_speed = carla_role_data[carla_role_data['lon_speed'] >= 2.0]['lon_speed']\n",
    "            argo_speed = argo_role_data[argo_role_data['lon_speed'] >= 2.0]['lon_speed']\n",
    "            \n",
    "            if len(carla_speed) > 0 and len(argo_speed) > 0:\n",
    "                # Calculate histograms\n",
    "                combined_max = max(carla_speed.max(), argo_speed.max())\n",
    "                bin_edges_speed = np.arange(2.0, combined_max + 1.0, 1.0)\n",
    "                \n",
    "                argo_hist, _ = np.histogram(argo_speed, bins=bin_edges_speed, density=True)\n",
    "                carla_hist, _ = np.histogram(carla_speed, bins=bin_edges_speed, density=True)\n",
    "                \n",
    "                # Find holes\n",
    "                high_threshold = 0.01\n",
    "                for i in range(len(bin_edges_speed) - 1):\n",
    "                    if argo_hist[i] >= high_threshold and carla_hist[i] < (argo_hist[i] * 0.1):\n",
    "                        # This bin is a hole - get Argoverse data in this range\n",
    "                        speed_min = bin_edges_speed[i]\n",
    "                        speed_max = bin_edges_speed[i+1]\n",
    "                        \n",
    "                        # Get Argoverse graphs with speeds in this range for this role\n",
    "                        argo_in_range = argo_role_data[\n",
    "                            (argo_role_data['lon_speed'] >= speed_min) & \n",
    "                            (argo_role_data['lon_speed'] < speed_max)\n",
    "                        ]\n",
    "                        \n",
    "                        for _, row in argo_in_range.iterrows():\n",
    "                            speed_holes_data.append({\n",
    "                                'scenario': scenario,\n",
    "                                'role': role,\n",
    "                                'speed_range_min': speed_min,\n",
    "                                'speed_range_max': speed_max,\n",
    "                                'argoverse_graph_path': row['path'],\n",
    "                                'argoverse_node_id': row['node_id'],\n",
    "                                'actual_speed': row['lon_speed'],\n",
    "                                'argo_density': argo_hist[i],\n",
    "                                'carla_density': carla_hist[i],\n",
    "                                'density_gap': argo_hist[i] - carla_hist[i]\n",
    "                            })\n",
    "            \n",
    "            # === PATH LENGTH HOLES ===\n",
    "            carla_role_node_ids = carla_role_data['node_id'].tolist()\n",
    "            argo_role_node_ids = argo_role_data['node_id'].tolist()\n",
    "            \n",
    "            carla_edge_data = [df for df in carla_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "            argo_edge_data = [df for df in argo_scenario_edges if df['scenario'].iloc[0] == scenario][0]\n",
    "            \n",
    "            carla_role_edges = carla_edge_data[carla_edge_data['source'].isin(carla_role_node_ids)]\n",
    "            argo_role_edges = argo_edge_data[argo_edge_data['source'].isin(argo_role_node_ids)]\n",
    "            \n",
    "            if len(carla_role_edges) > 0 and len(argo_role_edges) > 0:\n",
    "                # Calculate histograms\n",
    "                combined_max_path = max(carla_role_edges['path_length'].max(), argo_role_edges['path_length'].max())\n",
    "                bin_edges_path = np.arange(0.0, combined_max_path + 5.0, 5.0)\n",
    "                \n",
    "                argo_hist_path, _ = np.histogram(argo_role_edges['path_length'], bins=bin_edges_path, density=True)\n",
    "                carla_hist_path, _ = np.histogram(carla_role_edges['path_length'], bins=bin_edges_path, density=True)\n",
    "                \n",
    "                # Find holes\n",
    "                high_threshold_path = 0.01\n",
    "                for i in range(len(bin_edges_path) - 1):\n",
    "                    if argo_hist_path[i] >= high_threshold_path and carla_hist_path[i] < (argo_hist_path[i] * 0.1):\n",
    "                        # This bin is a hole - get Argoverse data in this range\n",
    "                        path_min = bin_edges_path[i]\n",
    "                        path_max = bin_edges_path[i+1]\n",
    "                        \n",
    "                        # Get Argoverse edges with path lengths in this range\n",
    "                        argo_in_range = argo_role_edges[\n",
    "                            (argo_role_edges['path_length'] >= path_min) & \n",
    "                            (argo_role_edges['path_length'] < path_max)\n",
    "                        ]\n",
    "                        \n",
    "                        for _, row in argo_in_range.iterrows():\n",
    "                            path_holes_data.append({\n",
    "                                'scenario': scenario,\n",
    "                                'role': role,\n",
    "                                'path_range_min': path_min,\n",
    "                                'path_range_max': path_max,\n",
    "                                'argoverse_graph_path': row['path'],\n",
    "                                'edge_source': row['source'],\n",
    "                                'edge_target': row['target'],\n",
    "                                'actual_path_length': row['path_length'],\n",
    "                                'argo_density': argo_hist_path[i],\n",
    "                                'carla_density': carla_hist_path[i],\n",
    "                                'density_gap': argo_hist_path[i] - carla_hist_path[i]\n",
    "                            })\n",
    "\n",
    "# Save to CSV\n",
    "speed_holes_df = pd.DataFrame(speed_holes_data)\n",
    "if len(speed_holes_df) > 0:\n",
    "    speed_holes_df.to_csv('coverage_holes/carla_speed_distribution_holes.csv', index=False)\n",
    "    print(f\"\\n    Saved {len(speed_holes_df)} Argoverse data points with missing speed ranges\")\n",
    "    print(f\"     File: coverage_holes/carla_speed_distribution_holes.csv\")\n",
    "else:\n",
    "    print(\"\\n   No speed distribution holes found\")\n",
    "\n",
    "path_holes_df = pd.DataFrame(path_holes_data)\n",
    "if len(path_holes_df) > 0:\n",
    "    path_holes_df.to_csv('coverage_holes/carla_path_distribution_holes.csv', index=False)\n",
    "    print(f\"    Saved {len(path_holes_df)} Argoverse data points with missing path ranges\")\n",
    "    print(f\"     File: coverage_holes/carla_path_distribution_holes.csv\")\n",
    "else:\n",
    "    print(\"   No path distribution holes found\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Speed/Path distribution export complete!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence matrix for CARLA - showing percentage where BOTH subgraphs are present together\n",
    "columns = list(coverage_graphs.keys())\n",
    "n_cols = len(columns)\n",
    "cooccurrence_matrix = np.zeros((n_cols, n_cols))\n",
    "\n",
    "for i, col1 in enumerate(columns):\n",
    "    for j, col2 in enumerate(columns):\n",
    "        if i == j:\n",
    "            # Diagonal: percentage where this subgraph is present\n",
    "            cooccurrence_matrix[i, j] = cov_data_df_carla[col1].sum() / len(cov_data_df_carla) * 100\n",
    "        else:\n",
    "            # Calculate percentage where BOTH subgraphs are present (co-occurrence)\n",
    "            cooccurrence = (cov_data_df_carla[col1] & cov_data_df_carla[col2]).sum() / len(cov_data_df_carla) * 100\n",
    "            cooccurrence_matrix[i, j] = cooccurrence\n",
    "\n",
    "# Create DataFrame for the heatmap\n",
    "cooccurrence_df_carla = pd.DataFrame(\n",
    "    cooccurrence_matrix,\n",
    "    index=columns,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# Keep backward compatibility with old variable name\n",
    "agreement_df_carla = cooccurrence_df_carla\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(agreement_df_carla, \n",
    "            annot=False,  # Too many cells to annotate\n",
    "            cmap='YlGnBu',\n",
    "            vmin=0, \n",
    "            vmax=100,\n",
    "            cbar_kws={'label': 'Agreement %'},\n",
    "            xticklabels=True,\n",
    "            yticklabels=True)\n",
    "plt.title('CARLA: Subgraph Co-occurrence Matrix\\n(Percentage of graphs where both subgraphs have same presence)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/carla_agreement_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence matrix for ARGOVERSE - showing percentage where BOTH subgraphs are present together\n",
    "columns = list(coverage_graphs.keys())\n",
    "n_cols = len(columns)\n",
    "cooccurrence_matrix = np.zeros((n_cols, n_cols))\n",
    "\n",
    "for i, col1 in enumerate(columns):\n",
    "    for j, col2 in enumerate(columns):\n",
    "        if i == j:\n",
    "            # Diagonal: percentage where this subgraph is present\n",
    "            cooccurrence_matrix[i, j] = cov_data_df_argo[col1].sum() / len(cov_data_df_argo) * 100\n",
    "        else:\n",
    "            # Calculate percentage where BOTH subgraphs are present (co-occurrence)\n",
    "            cooccurrence = (cov_data_df_argo[col1] & cov_data_df_argo[col2]).sum() / len(cov_data_df_argo) * 100\n",
    "            cooccurrence_matrix[i, j] = cooccurrence\n",
    "\n",
    "# Create DataFrame for the heatmap\n",
    "cooccurrence_df_argo = pd.DataFrame(\n",
    "    cooccurrence_matrix,\n",
    "    index=columns,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "# Keep backward compatibility with old variable name\n",
    "agreement_df_argo = cooccurrence_df_argo\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(agreement_df_argo, \n",
    "            annot=False,  # Too many cells to annotate\n",
    "            cmap='YlGnBu',\n",
    "            vmin=0, \n",
    "            vmax=100,\n",
    "            cbar_kws={'label': 'Agreement %'},\n",
    "            xticklabels=True,\n",
    "            yticklabels=True)\n",
    "plt.title('ARGOVERSE: Subgraph Co-occurrence Matrix\\n(Percentage of graphs where both subgraphs have same presence)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/argo_agreement_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis: Co-occurrence Matrix Holes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate co-occurrence holes for both datasets\n",
    "# This needs to be done after the agreement matrices are created\n",
    "\n",
    "def name_cooccurrence_hole(pattern1: str, pattern2: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a descriptive name for a co-occurrence hole based on the two patterns involved.\n",
    "    \n",
    "    Args:\n",
    "        pattern1: First subgraph pattern name\n",
    "        pattern2: Second subgraph pattern name\n",
    "    \n",
    "    Returns:\n",
    "        A descriptive name for the co-occurrence\n",
    "    \"\"\"\n",
    "    # Simplified pattern names for readability\n",
    "    name_map = {\n",
    "        'simple_2actor_overtaking': 'Overtaking',\n",
    "        'simple_2actor_following': 'Following',\n",
    "        'simple_2actor_merging': 'Merging',\n",
    "        'simple_2actor_crossing': 'Crossing',\n",
    "        'simple_2actor_oncoming': 'Oncoming',\n",
    "        'complex_3actor_chain': '3-Chain',\n",
    "        'complex_3actor_merge': '3-Merge',\n",
    "        'complex_3actor_split': '3-Split',\n",
    "        'complex_4actor_intersection': '4-Intersection',\n",
    "        'complex_multilane_weave': 'Weave'\n",
    "    }\n",
    "    \n",
    "    short1 = name_map.get(pattern1, pattern1.replace('simple_2actor_', '').replace('complex_', '').title())\n",
    "    short2 = name_map.get(pattern2, pattern2.replace('simple_2actor_', '').replace('complex_', '').title())\n",
    "    \n",
    "    return f\"{short1} + {short2}\"\n",
    "\n",
    "# Define thresholds\n",
    "argo_high_threshold = 10.0  # High co-occurrence threshold\n",
    "carla_low_threshold = 2.0  # Low co-occurrence threshold\n",
    "\n",
    "# Find co-occurrence holes in CARLA (high in Argo, low in CARLA)\n",
    "carla_cooccurrence_holes = []\n",
    "\n",
    "for i in range(len(agreement_df_carla)):\n",
    "    for j in range(i+1, len(agreement_df_carla)):  # Upper triangle only\n",
    "        argo_val = agreement_df_argo.iloc[i, j]\n",
    "        carla_val = agreement_df_carla.iloc[i, j]\n",
    "        \n",
    "        if argo_val >= argo_high_threshold and carla_val < carla_low_threshold:\n",
    "            pattern1 = agreement_df_carla.index[i]\n",
    "            pattern2 = agreement_df_carla.columns[j]\n",
    "            carla_cooccurrence_holes.append({\n",
    "                'name': name_cooccurrence_hole(pattern1, pattern2),\n",
    "                'pattern1': pattern1,\n",
    "                'pattern2': pattern2,\n",
    "                'argoverse_cooccurrence': argo_val,\n",
    "                'carla_cooccurrence': carla_val,\n",
    "                'difference': argo_val - carla_val\n",
    "            })\n",
    "\n",
    "# Sort by difference\n",
    "carla_cooccurrence_holes_df = pd.DataFrame(carla_cooccurrence_holes).sort_values('difference', ascending=False) if len(carla_cooccurrence_holes) > 0 else pd.DataFrame(carla_cooccurrence_holes)\n",
    "\n",
    "# Find co-occurrence holes in Argoverse (high in CARLA, low in Argo)\n",
    "argo_cooccurrence_holes = []\n",
    "\n",
    "for i in range(len(agreement_df_carla)):\n",
    "    for j in range(i+1, len(agreement_df_carla)):  # Upper triangle only\n",
    "        carla_val = agreement_df_carla.iloc[i, j]\n",
    "        argo_val = agreement_df_argo.iloc[i, j]\n",
    "        \n",
    "        if carla_val >= argo_high_threshold and argo_val < carla_low_threshold:\n",
    "            pattern1 = agreement_df_carla.index[i]\n",
    "            pattern2 = agreement_df_carla.columns[j]\n",
    "            argo_cooccurrence_holes.append({\n",
    "                'name': name_cooccurrence_hole(pattern1, pattern2),\n",
    "                'pattern1': pattern1,\n",
    "                'pattern2': pattern2,\n",
    "                'carla_cooccurrence': carla_val,\n",
    "                'argoverse_cooccurrence': argo_val,\n",
    "                'difference': carla_val - argo_val\n",
    "            })\n",
    "\n",
    "# Sort by difference\n",
    "argo_cooccurrence_holes_df = pd.DataFrame(argo_cooccurrence_holes).sort_values('difference', ascending=False) if len(argo_cooccurrence_holes) > 0 else pd.DataFrame(argo_cooccurrence_holes)\n",
    "\n",
    "print(f\"Calculated co-occurrence holes:\")\n",
    "print(f\"  - CARLA holes: {len(carla_cooccurrence_holes_df)}\")\n",
    "print(f\"  - Argoverse holes: {len(argo_cooccurrence_holes_df)}\")\n",
    "\n",
    "# Display the holes with names\n",
    "if len(carla_cooccurrence_holes_df) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CARLA Co-occurrence Holes (High in Argoverse, Low in CARLA):\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for idx, row in carla_cooccurrence_holes_df.iterrows():\n",
    "        print(f\"{idx+1}. {row['name']}\")\n",
    "        print(f\"   Argoverse: {row['argoverse_cooccurrence']:.1f}% | CARLA: {row['carla_cooccurrence']:.1f}% | Gap: {row['difference']:.1f}%\")\n",
    "\n",
    "if len(argo_cooccurrence_holes_df) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Argoverse Co-occurrence Holes (High in CARLA, Low in Argoverse):\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for idx, row in argo_cooccurrence_holes_df.iterrows():\n",
    "        print(f\"{idx+1}. {row['name']}\")\n",
    "        print(f\"   CARLA: {row['carla_cooccurrence']:.1f}% | Argoverse: {row['argoverse_cooccurrence']:.1f}% | Gap: {row['difference']:.1f}%\")\n",
    "\n",
    "# ================================================================================\n",
    "# EXPORT COVERAGE HOLES TO CSV\n",
    "# ================================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXPORTING COVERAGE HOLES TO CSV FILES\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "import os\n",
    "os.makedirs('coverage_holes', exist_ok=True)\n",
    "\n",
    "# 1. SUBGRAPH HOLES: Scenarios missing in CARLA\n",
    "# ------------------------------------------------\n",
    "print(\"1. Exporting subgraph holes...\")\n",
    "subgraph_holes_data = []\n",
    "\n",
    "for _, hole_row in comparison_df[comparison_df['hole_in_carla']].iterrows():\n",
    "    scenario_name = hole_row['subgraph']\n",
    "    # Get Argoverse graphs that contain this scenario\n",
    "    argo_graphs_with_scenario = cov_data_df_argo[cov_data_df_argo[scenario_name] == True]['path'].tolist()\n",
    "    \n",
    "    for graph_path in argo_graphs_with_scenario:\n",
    "        subgraph_holes_data.append({\n",
    "            'scenario': scenario_name,\n",
    "            'argoverse_graph_path': graph_path,\n",
    "            'argo_absolute_count': hole_row['absolute_count_argo'],\n",
    "            'argo_relative_percentage': hole_row['relative_percentage_argo'],\n",
    "            'carla_absolute_count': hole_row['absolute_count_carla'],\n",
    "            'carla_relative_percentage': hole_row['relative_percentage_carla'],\n",
    "            'coverage_gap': hole_row['abs_diff']\n",
    "        })\n",
    "\n",
    "subgraph_holes_df = pd.DataFrame(subgraph_holes_data)\n",
    "if len(subgraph_holes_df) > 0:\n",
    "    subgraph_holes_df.to_csv('coverage_holes/carla_subgraph_holes.csv', index=False)\n",
    "    print(f\"    Saved {len(subgraph_holes_df)} Argoverse graphs with missing scenarios\")\n",
    "    print(f\"     File: coverage_holes/carla_subgraph_holes.csv\")\n",
    "else:\n",
    "    print(\"   No subgraph holes found\")\n",
    "\n",
    "# 3. CO-OCCURRENCE HOLES: Scenario combinations missing in CARLA\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\n3. Exporting co-occurrence holes...\")\n",
    "cooccurrence_holes_data = []\n",
    "\n",
    "for _, hole_row in carla_cooccurrence_holes_df.iterrows():\n",
    "    pattern1 = hole_row['pattern1']\n",
    "    pattern2 = hole_row['pattern2']\n",
    "    \n",
    "    # Get Argoverse graphs that contain BOTH patterns\n",
    "    argo_graphs_with_both = cov_data_df_argo[\n",
    "        (cov_data_df_argo[pattern1] == True) & \n",
    "        (cov_data_df_argo[pattern2] == True)\n",
    "    ]['path'].tolist()\n",
    "    \n",
    "    for graph_path in argo_graphs_with_both:\n",
    "        cooccurrence_holes_data.append({\n",
    "            'combination_name': hole_row['name'],\n",
    "            'pattern1': pattern1,\n",
    "            'pattern2': pattern2,\n",
    "            'argoverse_graph_path': graph_path,\n",
    "            'argo_cooccurrence_rate': hole_row['argoverse_cooccurrence'],\n",
    "            'carla_cooccurrence_rate': hole_row['carla_cooccurrence'],\n",
    "            'cooccurrence_gap': hole_row['difference']\n",
    "        })\n",
    "\n",
    "cooccurrence_holes_df_export = pd.DataFrame(cooccurrence_holes_data)\n",
    "if len(cooccurrence_holes_df_export) > 0:\n",
    "    cooccurrence_holes_df_export.to_csv('coverage_holes/carla_cooccurrence_holes.csv', index=False)\n",
    "    print(f\"    Saved {len(cooccurrence_holes_df_export)} Argoverse graphs with missing combinations\")\n",
    "    print(f\"     File: coverage_holes/carla_cooccurrence_holes.csv\")\n",
    "else:\n",
    "    print(\"   No co-occurrence holes found\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CSV export complete!\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize co-occurrence difference matrix\n",
    "cooccurrence_diff = agreement_df_carla - agreement_df_argo\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "# Create difference heatmap\n",
    "sns.heatmap(cooccurrence_diff, \n",
    "            cmap='RdBu_r', \n",
    "            center=0, \n",
    "            vmin=-50, \n",
    "            vmax=50,\n",
    "            cbar_kws={'label': 'Co-occurrence Difference (CARLA - Argoverse) %'},\n",
    "            xticklabels=True,\n",
    "            yticklabels=True,\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Co-occurrence Difference Matrix: CARLA vs ARGOVERSE\\n' + \n",
    "             '(Red = More co-occurrence in CARLA, Blue = More in Argoverse)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/cooccurrence_difference_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nCo-occurrence Difference Summary Statistics:\")\n",
    "print(f\"  Mean absolute difference: {np.abs(cooccurrence_diff.values[np.triu_indices_from(cooccurrence_diff, k=1)]).mean():.2f}%\")\n",
    "print(f\"  Max positive difference (more in CARLA): {cooccurrence_diff.values.max():.2f}%\")\n",
    "print(f\"  Max negative difference (more in Argo): {cooccurrence_diff.values.min():.2f}%\")\n",
    "print(f\"  Pairs with >10% difference: {(np.abs(cooccurrence_diff.values[np.triu_indices_from(cooccurrence_diff, k=1)]) > 10).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
